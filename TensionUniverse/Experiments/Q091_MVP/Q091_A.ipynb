{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# TU Q091-A · Equilibrium climate sensitivity range reasoning (MVP, fixed OpenAI client)\n",
        "#\n",
        "# This notebook is designed as a single-cell Colab script:\n",
        "# 1. It defines a small synthetic item bank about equilibrium climate sensitivity (ECS).\n",
        "# 2. It asks a chat model to estimate ECS and explain the estimate.\n",
        "# 3. It probes the explanation and computes a scalar tension observable T_ECS_range.\n",
        "#\n",
        "# You can:\n",
        "# - Read the code and printed tables without running any live API calls.\n",
        "# - Optionally enter an OpenAI API key when prompted to reproduce the experiment.\n",
        "#   The key is requested via a hidden prompt and is NOT stored in the notebook text.\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "import math\n",
        "import json\n",
        "import textwrap\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Dict, Any, List\n",
        "\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 0. OpenAI client setup (new-style API)\n",
        "# ---------------------------------------------------------------------\n",
        "\n",
        "def ensure_openai_installed() -> None:\n",
        "    try:\n",
        "        from openai import OpenAI  # noqa: F401\n",
        "    except ImportError:\n",
        "        print(\"[setup] openai package not found. Installing openai>=1.0.0 ...\")\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", \"openai\"], check=False)\n",
        "\n",
        "\n",
        "def build_openai_client() -> Optional[\"OpenAI\"]:\n",
        "    \"\"\"\n",
        "    Ask the user whether to run live OpenAI calls.\n",
        "    If yes, request an API key via hidden input and build a client.\n",
        "    If the user skips the key, stay in offline mode.\n",
        "    \"\"\"\n",
        "    ensure_openai_installed()\n",
        "    from openai import OpenAI  # type: ignore\n",
        "\n",
        "    choice = input(\n",
        "        \"\\n[Q091-A] Run with live OpenAI calls? (y/n) \"\n",
        "        \"(n = offline mode, just show item bank and exit): \"\n",
        "    ).strip().lower()\n",
        "\n",
        "    if choice != \"y\":\n",
        "        print(\"\\n[mode] Offline mode selected. \"\n",
        "              \"No OpenAI calls will be made. \"\n",
        "              \"You can still inspect the item bank and code.\")\n",
        "        return None\n",
        "\n",
        "    api_key = getpass(\"\\n[secure] Enter your OpenAI API key (input is hidden). \"\n",
        "                      \"Press Enter to cancel and stay offline: \").strip()\n",
        "\n",
        "    if not api_key:\n",
        "        print(\"\\n[mode] No API key provided. Staying in offline mode.\")\n",
        "        return None\n",
        "\n",
        "    # Build client with explicit API key (not printed anywhere).\n",
        "    client = OpenAI(api_key=api_key)\n",
        "    print(\"\\n[setup] OpenAI client initialised. \"\n",
        "          \"Model calls will use your key inside this runtime only.\")\n",
        "    return client\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 1. Data structures and synthetic item bank\n",
        "# ---------------------------------------------------------------------\n",
        "\n",
        "ECS_GLOBAL_MIN = 0.5\n",
        "ECS_GLOBAL_MAX = 6.0\n",
        "\n",
        "@dataclass\n",
        "class ECSItem:\n",
        "    item_id: str\n",
        "    title: str\n",
        "    bucket_true: str\n",
        "    ecs_min_true: float\n",
        "    ecs_max_true: float\n",
        "\n",
        "\n",
        "def build_item_bank() -> List[ECSItem]:\n",
        "    \"\"\"\n",
        "    Synthetic item bank for equilibrium climate sensitivity reasoning.\n",
        "    These items are not real datasets. They are stylised descriptions\n",
        "    used to probe consistency at the effective layer.\n",
        "    \"\"\"\n",
        "    items = [\n",
        "        ECSItem(\n",
        "            item_id=\"C01\",\n",
        "            title=\"Historical warming with multi-line evidence (medium ECS)\",\n",
        "            bucket_true=\"MEDIUM\",\n",
        "            ecs_min_true=2.0,\n",
        "            ecs_max_true=4.0,\n",
        "        ),\n",
        "        ECSItem(\n",
        "            item_id=\"C02\",\n",
        "            title=\"Paleoclimate strong-response case (high ECS)\",\n",
        "            bucket_true=\"HIGH\",\n",
        "            ecs_min_true=4.0,\n",
        "            ecs_max_true=6.0,\n",
        "        ),\n",
        "        ECSItem(\n",
        "            item_id=\"C03\",\n",
        "            title=\"Energy-balance study with weak feedbacks (low ECS)\",\n",
        "            bucket_true=\"LOW\",\n",
        "            ecs_min_true=1.0,\n",
        "            ecs_max_true=2.0,\n",
        "        ),\n",
        "        ECSItem(\n",
        "            item_id=\"C04\",\n",
        "            title=\"Multi-source constraint narrowing around 2.5–3.0°C\",\n",
        "            bucket_true=\"MEDIUM\",\n",
        "            ecs_min_true=2.5,\n",
        "            ecs_max_true=3.5,\n",
        "        ),\n",
        "        ECSItem(\n",
        "            item_id=\"C05\",\n",
        "            title=\"High-end ensemble member emphasising strong positive feedbacks\",\n",
        "            bucket_true=\"HIGH\",\n",
        "            ecs_min_true=4.0,\n",
        "            ecs_max_true=5.5,\n",
        "        ),\n",
        "        ECSItem(\n",
        "            item_id=\"C06\",\n",
        "            title=\"Historical-only fit with cautious priors (medium ECS)\",\n",
        "            bucket_true=\"MEDIUM\",\n",
        "            ecs_min_true=1.8,\n",
        "            ecs_max_true=4.2,\n",
        "        ),\n",
        "        ECSItem(\n",
        "            item_id=\"C07\",\n",
        "            title=\"Short-term variability emphasised, but multiple lines of evidence\",\n",
        "            bucket_true=\"MEDIUM\",\n",
        "            ecs_min_true=2.0,\n",
        "            ecs_max_true=3.5,\n",
        "        ),\n",
        "        ECSItem(\n",
        "            item_id=\"C08\",\n",
        "            title=\"Hypothetical strong-stabilising feedback world (very low ECS)\",\n",
        "            bucket_true=\"LOW\",\n",
        "            ecs_min_true=0.5,\n",
        "            ecs_max_true=1.5,\n",
        "        ),\n",
        "    ]\n",
        "    return items\n",
        "\n",
        "\n",
        "def item_bank_dataframe(items: List[ECSItem]) -> pd.DataFrame:\n",
        "    rows = [\n",
        "        {\n",
        "            \"item_id\": it.item_id,\n",
        "            \"title\": it.title,\n",
        "            \"bucket_true\": it.bucket_true,\n",
        "            \"ecs_min_true\": it.ecs_min_true,\n",
        "            \"ecs_max_true\": it.ecs_max_true,\n",
        "        }\n",
        "        for it in items\n",
        "    ]\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 2. Helper functions for JSON parsing and scoring\n",
        "# ---------------------------------------------------------------------\n",
        "\n",
        "def extract_json_from_text(text: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Extract a JSON object from a chat completion.\n",
        "    The model is told to respond with pure JSON, but we defensively\n",
        "    strip extra text or Markdown fences if present.\n",
        "    \"\"\"\n",
        "    first = text.find(\"{\")\n",
        "    last = text.rfind(\"}\")\n",
        "    if first == -1 or last == -1 or last <= first:\n",
        "        raise ValueError(\"No JSON object found in model output.\")\n",
        "    json_str = text[first : last + 1]\n",
        "    return json.loads(json_str)\n",
        "\n",
        "\n",
        "def normalise_bucket(raw: Optional[str]) -> Optional[str]:\n",
        "    if raw is None:\n",
        "        return None\n",
        "    s = raw.strip().upper()\n",
        "    if \"LOW\" in s:\n",
        "        return \"LOW\"\n",
        "    if \"HIGH\" in s:\n",
        "        return \"HIGH\"\n",
        "    if \"MED\" in s:\n",
        "        return \"MEDIUM\"\n",
        "    return None\n",
        "\n",
        "\n",
        "def compute_range_plausibility(\n",
        "    ecs_low: Optional[float],\n",
        "    ecs_high: Optional[float],\n",
        "    global_min: float,\n",
        "    global_max: float,\n",
        ") -> float:\n",
        "    if ecs_low is None or ecs_high is None:\n",
        "        return 0.0\n",
        "    if ecs_high <= ecs_low:\n",
        "        return 0.0\n",
        "    width = ecs_high - ecs_low\n",
        "    overlap_low = max(ecs_low, global_min)\n",
        "    overlap_high = min(ecs_high, global_max)\n",
        "    overlap = max(0.0, overlap_high - overlap_low)\n",
        "    if overlap <= 0.0:\n",
        "        return 0.0\n",
        "    ratio = overlap / width\n",
        "    return max(0.0, min(1.0, ratio))\n",
        "\n",
        "\n",
        "def compute_bucket_correctness(\n",
        "    bucket_true: str,\n",
        "    bucket_estimate: Optional[str],\n",
        "    bucket_from_explanation: Optional[str],\n",
        ") -> float:\n",
        "    score = 0.0\n",
        "    if bucket_estimate is not None and bucket_estimate == bucket_true:\n",
        "        score += 0.5\n",
        "    if bucket_from_explanation is not None and bucket_from_explanation == bucket_true:\n",
        "        score += 0.5\n",
        "    return score\n",
        "\n",
        "\n",
        "def compute_self_consistency(\n",
        "    bucket_estimate: Optional[str],\n",
        "    bucket_from_explanation: Optional[str],\n",
        ") -> float:\n",
        "    if bucket_estimate is None or bucket_from_explanation is None:\n",
        "        return 0.0\n",
        "    return 1.0 if bucket_estimate == bucket_from_explanation else 0.0\n",
        "\n",
        "\n",
        "def compute_sharpness(\n",
        "    ecs_low: Optional[float],\n",
        "    ecs_high: Optional[float],\n",
        "    global_min: float,\n",
        "    global_max: float,\n",
        ") -> float:\n",
        "    if ecs_low is None or ecs_high is None:\n",
        "        return 0.0\n",
        "    if ecs_high <= ecs_low:\n",
        "        return 0.0\n",
        "    band_width = ecs_high - ecs_low\n",
        "    global_width = max(1e-6, global_max - global_min)\n",
        "    ratio = min(1.0, band_width / global_width)\n",
        "    return max(0.0, 1.0 - ratio)\n",
        "\n",
        "\n",
        "def combine_tension(\n",
        "    range_plausibility: float,\n",
        "    bucket_correctness: float,\n",
        "    self_consistency: float,\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Combine three scores into a scalar tension T_ECS_range in [0, 1].\n",
        "    Higher T means more tension (worse behavior).\n",
        "    \"\"\"\n",
        "    w_plaus = 0.4\n",
        "    w_bucket = 0.4\n",
        "    w_self = 0.2\n",
        "\n",
        "    t = (\n",
        "        w_plaus * (1.0 - range_plausibility)\n",
        "        + w_bucket * (1.0 - bucket_correctness)\n",
        "        + w_self * (1.0 - self_consistency)\n",
        "    ) / (w_plaus + w_bucket + w_self)\n",
        "\n",
        "    return max(0.0, min(1.0, t))\n",
        "\n",
        "\n",
        "def is_effectively_coherent(\n",
        "    range_plausibility: float,\n",
        "    bucket_correctness: float,\n",
        "    self_consistency: float,\n",
        "    t_ecs_range: float,\n",
        ") -> bool:\n",
        "    return (\n",
        "        range_plausibility >= 0.7\n",
        "        and bucket_correctness >= 0.7\n",
        "        and self_consistency >= 0.7\n",
        "        and t_ecs_range <= 0.4\n",
        "    )\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 3. Prompt builders and model calls\n",
        "# ---------------------------------------------------------------------\n",
        "\n",
        "def build_estimate_messages(item: ECSItem) -> List[Dict[str, str]]:\n",
        "    description = textwrap.dedent(\n",
        "        f\"\"\"\n",
        "        You are an assistant reasoning about equilibrium climate sensitivity (ECS).\n",
        "\n",
        "        Item id: {item.item_id}\n",
        "        Title: {item.title}\n",
        "\n",
        "        Think of ECS as the long-run global mean surface temperature change (in °C)\n",
        "        after a doubling of atmospheric CO₂.\n",
        "\n",
        "        Step 1: Read the description and imagine a stylised evidence pattern.\n",
        "        Step 2: Give a point estimate ECS_est in °C per CO₂ doubling.\n",
        "        Step 3: Give a 66% confidence interval [ECS_low, ECS_high].\n",
        "        Step 4: Assign a qualitative bucket:\n",
        "            - \"LOW\" if ECS is roughly below 2°C,\n",
        "            - \"MEDIUM\" if ECS is roughly between about 2–4.5°C,\n",
        "            - \"HIGH\" if ECS is clearly above about 4.5°C.\n",
        "\n",
        "        Respond ONLY with a JSON object, no Markdown, with keys:\n",
        "            \"ecs_estimate\": float,\n",
        "            \"ecs_low\": float,\n",
        "            \"ecs_high\": float,\n",
        "            \"bucket_estimate\": \"LOW\" | \"MEDIUM\" | \"HIGH\",\n",
        "            \"explanation\": string\n",
        "\n",
        "        The explanation should be 3–6 sentences in plain English.\n",
        "        \"\"\"\n",
        "    ).strip()\n",
        "\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": \"You are a careful climate reasoning assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": description},\n",
        "    ]\n",
        "\n",
        "\n",
        "def build_probe_messages(explanation: str) -> List[Dict[str, str]]:\n",
        "    instruction = textwrap.dedent(\n",
        "        f\"\"\"\n",
        "        You are checking the internal consistency of a climate sensitivity explanation.\n",
        "\n",
        "        Below is an explanation that discusses equilibrium climate sensitivity (ECS).\n",
        "        Your job is to infer which qualitative ECS bucket it supports.\n",
        "\n",
        "        Explanation:\n",
        "        \\\"\\\"\\\"{explanation}\\\"\\\"\\\"\n",
        "\n",
        "        Buckets:\n",
        "            - \"LOW\"    : ECS clearly below about 2°C per CO₂ doubling.\n",
        "            - \"MEDIUM\" : ECS in the broad 2–4.5°C range.\n",
        "            - \"HIGH\"   : ECS clearly above about 4.5°C.\n",
        "\n",
        "        Respond ONLY with a JSON object, no Markdown, with keys:\n",
        "            \"bucket_from_explanation\": \"LOW\" | \"MEDIUM\" | \"HIGH\",\n",
        "            \"confidence\": float between 0 and 1\n",
        "\n",
        "        The confidence is how sure you are that the explanation points to that bucket.\n",
        "        \"\"\"\n",
        "    ).strip()\n",
        "\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": \"You are a strict consistency checker.\"},\n",
        "        {\"role\": \"user\", \"content\": instruction},\n",
        "    ]\n",
        "\n",
        "\n",
        "def call_chat_json(\n",
        "    client: \"OpenAI\",\n",
        "    model: str,\n",
        "    messages: List[Dict[str, str]],\n",
        "    temperature: float = 0.2,\n",
        ") -> Dict[str, Any]:\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "    )\n",
        "    content = response.choices[0].message.content\n",
        "    return extract_json_from_text(content)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 4. Main experiment loop\n",
        "# ---------------------------------------------------------------------\n",
        "\n",
        "def run_q091_a(client: Optional[\"OpenAI\"]) -> None:\n",
        "    print(\"\\n=== TU Q091-A · Equilibrium climate sensitivity range reasoning (MVP) ===\\n\")\n",
        "\n",
        "    items = build_item_bank()\n",
        "    df_items = item_bank_dataframe(items)\n",
        "\n",
        "    print(\"=== TU Q091-A: Synthetic item bank (equilibrium climate sensitivity) ===\")\n",
        "    print(df_items)\n",
        "    print(\n",
        "        \"\\nNote: These items are synthetic and only used to test consistency of reasoning \"\n",
        "        \"at the effective layer.\\n\"\n",
        "    )\n",
        "\n",
        "    if client is None:\n",
        "        print(\n",
        "            \"[info] No OpenAI client available. \"\n",
        "            \"Experiment will not run live calls.\\n\"\n",
        "            \"You can inspect this cell, the item bank, and the README without any API usage.\\n\"\n",
        "        )\n",
        "        return\n",
        "\n",
        "    model_name = \"gpt-4o-mini\"\n",
        "    print(f\"[run] Starting TU Q091-A experiment with live OpenAI calls on model '{model_name}' ...\\n\")\n",
        "\n",
        "    results: List[Dict[str, Any]] = []\n",
        "\n",
        "    for item in items:\n",
        "        print(f\"--- Running item {item.item_id} · {item.title} ---\")\n",
        "        ecs_estimate = None\n",
        "        ecs_low = None\n",
        "        ecs_high = None\n",
        "        bucket_estimate = None\n",
        "        explanation = None\n",
        "        bucket_from_explanation = None\n",
        "        range_plausibility = 0.0\n",
        "        bucket_correctness = 0.0\n",
        "        self_consistency = 0.0\n",
        "        sharpness = 0.0\n",
        "        t_ecs_range = 1.0\n",
        "        coherent_flag = False\n",
        "\n",
        "        try:\n",
        "            # Step 1: estimate ECS and explanation\n",
        "            est_messages = build_estimate_messages(item)\n",
        "            est_json = call_chat_json(client, model_name, est_messages, temperature=0.2)\n",
        "\n",
        "            ecs_estimate = float(est_json.get(\"ecs_estimate\", None))\n",
        "            ecs_low = float(est_json.get(\"ecs_low\", None))\n",
        "            ecs_high = float(est_json.get(\"ecs_high\", None))\n",
        "            bucket_estimate = normalise_bucket(est_json.get(\"bucket_estimate\"))\n",
        "            explanation = str(est_json.get(\"explanation\", \"\")).strip()\n",
        "\n",
        "            # Step 2: probe explanation only\n",
        "            probe_messages = build_probe_messages(explanation)\n",
        "            probe_json = call_chat_json(client, model_name, probe_messages, temperature=0.0)\n",
        "            bucket_from_explanation = normalise_bucket(\n",
        "                probe_json.get(\"bucket_from_explanation\")\n",
        "            )\n",
        "\n",
        "            # Step 3: compute scores\n",
        "            range_plausibility = compute_range_plausibility(\n",
        "                ecs_low, ecs_high, ECS_GLOBAL_MIN, ECS_GLOBAL_MAX\n",
        "            )\n",
        "            bucket_correctness = compute_bucket_correctness(\n",
        "                item.bucket_true, bucket_estimate, bucket_from_explanation\n",
        "            )\n",
        "            self_consistency = compute_self_consistency(\n",
        "                bucket_estimate, bucket_from_explanation\n",
        "            )\n",
        "            sharpness = compute_sharpness(\n",
        "                ecs_low, ecs_high, ECS_GLOBAL_MIN, ECS_GLOBAL_MAX\n",
        "            )\n",
        "            t_ecs_range = combine_tension(\n",
        "                range_plausibility, bucket_correctness, self_consistency\n",
        "            )\n",
        "            coherent_flag = is_effectively_coherent(\n",
        "                range_plausibility,\n",
        "                bucket_correctness,\n",
        "                self_consistency,\n",
        "                t_ecs_range,\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[error] OpenAI call or parsing failed for item {item.item_id}: {e}\")\n",
        "            print(\"[info] Marking this item as maximal tension (T_ECS_range = 1.0).\")\n",
        "\n",
        "        results.append(\n",
        "            {\n",
        "                \"item_id\": item.item_id,\n",
        "                \"title\": item.title,\n",
        "                \"bucket_true\": item.bucket_true,\n",
        "                \"ecs_estimate\": ecs_estimate,\n",
        "                \"ecs_low\": ecs_low,\n",
        "                \"ecs_high\": ecs_high,\n",
        "                \"bucket_estimate\": bucket_estimate,\n",
        "                \"bucket_from_explanation\": bucket_from_explanation,\n",
        "                \"range_plausibility\": range_plausibility,\n",
        "                \"bucket_correctness\": bucket_correctness,\n",
        "                \"self_consistency\": self_consistency,\n",
        "                \"sharpness\": sharpness,\n",
        "                \"T_ECS_range\": t_ecs_range,\n",
        "                \"is_effective_coherent\": coherent_flag,\n",
        "            }\n",
        "        )\n",
        "\n",
        "        print(\n",
        "            f\"    range_plausibility = {range_plausibility:.2f} | \"\n",
        "            f\"bucket_correctness = {bucket_correctness:.2f} | \"\n",
        "            f\"self_consistency = {self_consistency:.2f} | \"\n",
        "            f\"T_ECS_range = {t_ecs_range:.2f} | \"\n",
        "            f\"coherent = {coherent_flag}\"\n",
        "        )\n",
        "        print()\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "\n",
        "    print(\"\\n=== Summary table (one row per item) ===\")\n",
        "    print(df)\n",
        "\n",
        "    # Overall statistics\n",
        "    print(\"\\n=== Overall statistics ===\")\n",
        "    mean_t = float(df[\"T_ECS_range\"].mean())\n",
        "    median_t = float(df[\"T_ECS_range\"].median())\n",
        "    coherent_rate = float(df[\"is_effective_coherent\"].mean())\n",
        "    print(f\"mean T_ECS_range   : {mean_t:5.3f}\")\n",
        "    print(f\"median T_ECS_range : {median_t:5.3f}\")\n",
        "    print(f\"coherent item rate : {coherent_rate:5.3f}\")\n",
        "\n",
        "    # Mean tension by bucket\n",
        "    print(\"\\n=== Mean tension by ground-truth bucket ===\")\n",
        "    df_bucket = (\n",
        "        df.groupby(\"bucket_true\")[\"T_ECS_range\"]\n",
        "        .agg([\"mean\", \"median\", \"count\"])\n",
        "        .reset_index()\n",
        "        .sort_values(\"bucket_true\")\n",
        "    )\n",
        "    print(df_bucket)\n",
        "\n",
        "    # -----------------------------------------------------------------\n",
        "    # 5. Plots\n",
        "    # -----------------------------------------------------------------\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.bar(df[\"item_id\"], df[\"T_ECS_range\"])\n",
        "    plt.ylim(0.0, 1.0)\n",
        "    plt.xlabel(\"Item id\")\n",
        "    plt.ylabel(\"T_ECS_range\")\n",
        "    plt.title(\"TU Q091-A: T_ECS_range per item\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    df_bucket_mean = (\n",
        "        df.groupby(\"bucket_true\")[\"T_ECS_range\"]\n",
        "        .mean()\n",
        "        .reset_index()\n",
        "        .sort_values(\"bucket_true\")\n",
        "    )\n",
        "    plt.bar(df_bucket_mean[\"bucket_true\"], df_bucket_mean[\"T_ECS_range\"])\n",
        "    plt.ylim(0.0, 1.0)\n",
        "    plt.xlabel(\"Ground-truth bucket\")\n",
        "    plt.ylabel(\"Mean T_ECS_range\")\n",
        "    plt.title(\"TU Q091-A: mean T_ECS_range by bucket\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\n",
        "        \"\\n[done] TU Q091-A run completed. \"\n",
        "        \"You can screenshot the tables and plots, or compare with future runs.\"\n",
        "    )\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 6. Entry point\n",
        "# ---------------------------------------------------------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    client_obj = build_openai_client()\n",
        "    run_q091_a(client_obj)\n"
      ],
      "metadata": {
        "id": "cmTBIDBZX6vS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}